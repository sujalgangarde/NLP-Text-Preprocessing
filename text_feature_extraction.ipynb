{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "822407ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-learn gensim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff40e360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# FEATURE EXTRACTION FOR ML\n",
    "# -------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Load Data\n",
    "# -------------------------------\n",
    "data = pd.DataFrame({\n",
    "    'text': [\n",
    "        \"Natural Language Processing is amazing\",\n",
    "        \"Text preprocessing cleans and prepares data\",\n",
    "        \"Feature extraction turns text into numbers\"\n",
    "    ]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bffc0938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of Words:\n",
      "    amazing  and  cleans  data  extraction  feature  into  is  language  \\\n",
      "0        1    0       0     0           0        0     0   1         1   \n",
      "1        0    1       1     1           0        0     0   0         0   \n",
      "2        0    0       0     0           1        1     1   0         0   \n",
      "\n",
      "   natural  numbers  prepares  preprocessing  processing  text  turns  \n",
      "0        1        0         0              0           1     0      0  \n",
      "1        0        0         1              1           0     1      0  \n",
      "2        0        1         0              0           0     1      1  \n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 2. Bag of Words\n",
    "# -------------------------------\n",
    "cv = CountVectorizer()\n",
    "bow = cv.fit_transform(data['text'])\n",
    "bow_df = pd.DataFrame(bow.toarray(), columns=cv.get_feature_names_out())\n",
    "print(\"Bag of Words:\\n\", bow_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7baef794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF:\n",
      "     amazing       and    cleans      data  extraction   feature      into  \\\n",
      "0  0.447214  0.000000  0.000000  0.000000    0.000000  0.000000  0.000000   \n",
      "1  0.000000  0.423394  0.423394  0.423394    0.000000  0.000000  0.000000   \n",
      "2  0.000000  0.000000  0.000000  0.000000    0.423394  0.423394  0.423394   \n",
      "\n",
      "         is  language   natural   numbers  prepares  preprocessing  \\\n",
      "0  0.447214  0.447214  0.447214  0.000000  0.000000       0.000000   \n",
      "1  0.000000  0.000000  0.000000  0.000000  0.423394       0.423394   \n",
      "2  0.000000  0.000000  0.000000  0.423394  0.000000       0.000000   \n",
      "\n",
      "   processing      text     turns  \n",
      "0    0.447214  0.000000  0.000000  \n",
      "1    0.000000  0.322002  0.000000  \n",
      "2    0.000000  0.322002  0.423394  \n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 3. TF-IDF\n",
    "# -------------------------------\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf.fit_transform(data['text'])\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf.get_feature_names_out())\n",
    "print(\"TF-IDF:\\n\", tfidf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61fc090d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector for 'text': [-1.07247464e-03  4.72871558e-04  1.02068903e-02  1.80188827e-02\n",
      " -1.86062474e-02 -1.42338844e-02  1.29179871e-02  1.79463141e-02\n",
      " -1.00310445e-02 -7.52688432e-03  1.47612859e-02 -3.06700030e-03\n",
      " -9.07339714e-03  1.31083494e-02 -9.72050335e-03 -3.63210333e-03\n",
      "  5.75326756e-03  1.98378484e-03 -1.65707413e-02 -1.88979898e-02\n",
      "  1.46238059e-02  1.01407142e-02  1.35156401e-02  1.52575970e-03\n",
      "  1.27020190e-02 -6.81085931e-03 -1.89283828e-03  1.15373628e-02\n",
      " -1.50435576e-02 -7.87235424e-03 -1.50234457e-02 -1.86011929e-03\n",
      "  1.90765951e-02 -1.46386083e-02 -4.66762483e-03 -3.87555477e-03\n",
      "  1.61551777e-02 -1.18620144e-02  9.03265754e-05 -9.50764585e-03\n",
      " -1.92074608e-02  1.00147743e-02 -1.75194982e-02 -8.78381543e-03\n",
      " -7.02012840e-05 -5.92374010e-04 -1.53227672e-02  1.92298461e-02\n",
      "  9.96430311e-03  1.84666328e-02]\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 4. Word2Vec\n",
    "# -------------------------------\n",
    "tokenized_data = [sentence.lower().split() for sentence in data['text']]\n",
    "w2v_model = Word2Vec(sentences=tokenized_data, vector_size=50, window=3, min_count=1, workers=4)\n",
    "print(\"Vector for 'text':\", w2v_model.wv['text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
